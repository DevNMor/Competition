{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f9d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede138e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('Preprocessing_Train.pkl')\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.document_text, train.label, test_size=0.25)\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "non_neg_stop = [i for i in stop_words if \"n't\" not in i and \"no\" not in i]\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def pos(x):\n",
    "    if x.startswith('J'):\n",
    "        return 'a'\n",
    "    elif x.startswith('V'):\n",
    "        return 'v'\n",
    "    elif x.startswith('R'):\n",
    "        return 'r'\n",
    "    else:\n",
    "        return 'n'\n",
    "    \n",
    "    \n",
    "def tok(doc, non_neg=False, lemmatized=False):\n",
    "    \n",
    "    if non_neg:\n",
    "        stop = non_neg_stop\n",
    "    else:\n",
    "        stop = stop_words\n",
    "       \n",
    "    tokens = re.split(r'\\s', doc.lower())\n",
    "    \n",
    "    if lemmatized:\n",
    "        pos_list = nltk.pos_tag(tokens)\n",
    "        tokens = list(map(lambda x: lemma.lemmatize(x[0], pos(x[1])), pos_list))    \n",
    "\n",
    "    tokens = [i for i in tokens if i not in stop]\n",
    "    tokens = [i for i in tokens if len(re.findall(r'\\w', i)) >= 2]\n",
    "    tokens = [re.findall(r\"\\w[a-zA-Z0-9.-]*\\w\", i)[0] for i in tokens if re.findall(r\"\\w[a-zA-Z0-9.-]*\\w\", i)]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "\n",
    "def get_voc_new(X, non_neg=True, lemmatized=True):\n",
    "    \n",
    "    voc = []\n",
    "    token_list = []\n",
    "    for i in X:\n",
    "        tokens = tok(i, non_neg, lemmatized)\n",
    "        token_list.append(tokens)\n",
    "        voc += tokens\n",
    "        \n",
    "    voc = list(set(voc))\n",
    "    \n",
    "    return voc, token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c050938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc, tk_list_train = get_voc_new(X_train, False, True)\n",
    "# voc, tk_list_train = get_voc_new(train.document_text, False, True)\n",
    "voc_test, tk_list_test = get_voc_new(X_test, False, True)\n",
    "voc_dic = {item: idx+1 for idx, item in enumerate(voc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c131662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(token_list):\n",
    "    \n",
    "    token_idx = []\n",
    "    for sent in token_list:\n",
    "        sent_list = []\n",
    "        for token in sent:\n",
    "            if token in voc_dic:\n",
    "                idx = voc_dic[token]\n",
    "            else:\n",
    "                idx = 0\n",
    "            sent_list.append(idx)\n",
    "        token_idx.append(sent_list)\n",
    "\n",
    "    return token_idx\n",
    "\n",
    "\n",
    "tk_idx_train = word2idx(tk_list_train)\n",
    "tk_idx_test = word2idx(tk_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39dbd6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_(Dataset):\n",
    "    \n",
    "    def __init__(self, X, y, max_len=1024):\n",
    "        super(dataset_, self).__init__()\n",
    "        pad = [i[:max_len] + [0]*(max_len-len(i[:max_len])) for i in X]\n",
    "        self.X = torch.tensor(pad, dtype=torch.int32)\n",
    "        self.y = torch.Tensor(np.array(list(y))[:, [8, 9, 22, 35]])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    \n",
    "train_ = dataset_(tk_idx_train, y_train)\n",
    "# train_ = dataset_(tk_idx_train, train.label)\n",
    "test_ = dataset_(tk_idx_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b26f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emb(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, dim_emb):\n",
    "        super(Emb, self).__init__()\n",
    "        self.emb = nn.Sequential(\n",
    "            nn.Embedding(voc_size, dim_emb, padding_idx=0),\n",
    "            nn.Linear(dim_emb, 256),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x)\n",
    "\n",
    "    \n",
    "class Conv1(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_emb, dim_out):\n",
    "        super(Conv1, self).__init__()\n",
    "        self.cv1 = nn.Sequential(\n",
    "            nn.Conv1d(dim_emb, dim_out, 1),\n",
    "            nn.BatchNorm1d(dim_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, 2))\n",
    "        self.cv2 = nn.Sequential(\n",
    "            nn.Conv1d(dim_emb, dim_out, 2),\n",
    "            nn.BatchNorm1d(dim_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, 2)) \n",
    "        self.cv3 = nn.Sequential(\n",
    "            nn.Conv1d(dim_emb, dim_out, 3),\n",
    "            nn.BatchNorm1d(dim_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        C1 = self.cv1(x.transpose(-2, -1)).transpose(-2, -1)\n",
    "        C2 = self.cv2(x.transpose(-2, -1)).transpose(-2, -1)\n",
    "        C3 = self.cv3(x.transpose(-2, -1)).transpose(-2, -1)\n",
    "        return torch.cat([C1,C2,C3], dim=-1)\n",
    "    \n",
    "class Conv2(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_emb, dim_out):\n",
    "        super(Conv2, self).__init__()\n",
    "        self.cv1 = nn.Sequential(\n",
    "            nn.Conv1d(dim_emb, dim_out, 1),\n",
    "            nn.BatchNorm1d(dim_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4, 2))\n",
    "        self.cv2 = nn.Sequential(\n",
    "            nn.Conv1d(dim_emb, dim_out, 2),\n",
    "            nn.BatchNorm1d(dim_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(3, 2)) \n",
    "        self.cv3 = nn.Sequential(\n",
    "            nn.Conv1d(dim_emb, dim_out, 3),\n",
    "            nn.BatchNorm1d(dim_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        C1 = self.cv1(x.transpose(-2, -1)).transpose(-2, -1)\n",
    "        C2 = self.cv2(x.transpose(-2, -1)).transpose(-2, -1)\n",
    "        C3 = self.cv3(x.transpose(-2, -1)).transpose(-2, -1)\n",
    "        return torch.cat([C1,C2,C3], dim=-1)\n",
    "    \n",
    "    \n",
    "class EndConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_emb, dim_out, conv_size):\n",
    "        super(EndConv, self).__init__()\n",
    "        self.ecv = nn.Sequential(\n",
    "            nn.Conv1d(dim_emb, dim_out, conv_size),\n",
    "            nn.BatchNorm1d(dim_out),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        Z = self.ecv(x.transpose(-2, -1))\n",
    "        return nn.MaxPool1d(Z.size(-1))(Z).squeeze(-1)\n",
    "    \n",
    "            \n",
    "class Att(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_emb=256, dim_enc=128):\n",
    "        super(Att, self).__init__()\n",
    "        self.Wq = nn.Linear(dim_emb, dim_enc, bias=False)\n",
    "        self.Wk = nn.Linear(dim_emb, dim_emb, bias=False)\n",
    "        self.Wv = nn.Linear(dim_emb, dim_emb, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        K = self.Wk(x)\n",
    "        V = self.Wv(x)\n",
    "        temp = self.Wq(K) \n",
    "        score = temp.transpose(-2, -1) / math.sqrt(K.size(-1)) ## (50, 1200)\n",
    "        return torch.matmul(nn.Softmax(dim=-1)(score), V)\n",
    "    \n",
    "    \n",
    "class LN(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_emb=256):\n",
    "        super(LN, self).__init__()\n",
    "        self.feed = nn.LayerNorm(dim_emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.feed(x)\n",
    "\n",
    "\n",
    "class final_model(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size=len(voc)+1, dim_emb=256, dropout=0.5, max_len=1024):\n",
    "        super(final_model, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            Emb(voc_size, dim_emb),  ## (1024, dim_emb)\n",
    "            Conv1(dim_emb, 128),\n",
    "            Conv2(384, 128),\n",
    "            EndConv(384, 256, 2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 4),\n",
    "            nn.Sigmoid())\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5e6e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataset, eval_dataset, device, norm=0.5,\n",
    "                lr=0.0005, epochs=50, batch_size=256):\n",
    "    \n",
    "    history = {'train_loss': [], 'eval_loss': [], 'detail_train': [], 'detail_eval': []}\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=batch_size)\n",
    "\n",
    "    model = model.to(device)\n",
    "    save_loss = nn.BCELoss(reduction='none').to(device)\n",
    "    \n",
    "    if norm:\n",
    "        Loss = nn.BCELoss(weight=train_.y.sum(axis=0)**-norm).to(device)\n",
    "\n",
    "    else:\n",
    "        Loss = nn.BCELoss().to(device)\n",
    "        \n",
    "    op = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    print('Training start!')\n",
    "    start = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        eval_loss = 0\n",
    "        detail_train = torch.zeros(4).to(device)\n",
    "        detail_eval = torch.zeros(4).to(device)\n",
    "        pred = []\n",
    "        real = []\n",
    "        \n",
    "        for X, y in train_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(X).squeeze(-1)\n",
    "            loss = Loss(out, y)\n",
    "            save_train = save_loss(out, y).sum(0)\n",
    "            \n",
    "            op.zero_grad()\n",
    "            loss.backward()\n",
    "            op.step()\n",
    "            \n",
    "            train_loss += loss\n",
    "            detail_train += save_train\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X, y in eval_loader:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                out = model(X).squeeze(-1)\n",
    "                loss = Loss(out, y)\n",
    "                save_eval = save_loss(out, y).sum(0)\n",
    "                detail_eval += save_eval\n",
    "                eval_loss += loss\n",
    "                pred.append(out.cpu())\n",
    "                real.append(y.cpu())\n",
    "                \n",
    "        train_loss = (train_loss/len(train_loader)).item()\n",
    "        eval_loss = (eval_loss/len(eval_loader)).item() \n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['eval_loss'].append(eval_loss)  \n",
    "        history['detail_train'].append(detail_train.cpu().detach())\n",
    "        history['detail_eval'].append(detail_eval.cpu().detach())  \n",
    "        \n",
    "        if not (epoch+1)%10:\n",
    "            print(f\"epoch {epoch+1}\\ntrain loss: {train_loss}\\t\\teval loss: {eval_loss}\")\n",
    "        \n",
    "        if not (epoch+1)%50:\n",
    "            res = torch.cat(pred)\n",
    "            tru = torch.cat(real)\n",
    "            print(f'\\nepoch {epoch+1}:\\n')\n",
    "            print(f\"f1_score for 50 classes: {f1_score(tru, np.round(res), average='macro')}\")\n",
    "            print(classification_report(tru, np.round(res), target_names=['8','9','22','35']))\n",
    "            print(f'\\nSpent time: {time.time()-start} seconds')\n",
    "            \n",
    "        \n",
    "    print('Training complete!')\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8859609",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start!\n",
      "epoch 10\n",
      "train loss: 0.002139141783118248\t\teval loss: 0.2321709245443344\n",
      "epoch 20\n",
      "train loss: 0.00026716693537309766\t\teval loss: 0.2790972888469696\n",
      "epoch 30\n",
      "train loss: 8.878252265276387e-05\t\teval loss: 0.2834634482860565\n",
      "epoch 40\n",
      "train loss: 4.307872222852893e-05\t\teval loss: 0.3233296871185303\n",
      "epoch 50\n",
      "train loss: 2.3913136828923598e-05\t\teval loss: 0.32576054334640503\n",
      "\n",
      "epoch 50:\n",
      "\n",
      "f1_score for 50 classes: 0.6105555098696266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.95      0.50      0.65       125\n",
      "           9       0.82      0.52      0.64       231\n",
      "          22       0.77      0.52      0.62       212\n",
      "          35       0.86      0.38      0.53       189\n",
      "\n",
      "   micro avg       0.83      0.48      0.61       757\n",
      "   macro avg       0.85      0.48      0.61       757\n",
      "weighted avg       0.84      0.48      0.61       757\n",
      " samples avg       0.13      0.13      0.13       757\n",
      "\n",
      "\n",
      "Spent time: 399.89486289024353 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60\n",
      "train loss: 1.380993035127176e-05\t\teval loss: 0.3238995373249054\n",
      "epoch 70\n",
      "train loss: 7.95444520917954e-06\t\teval loss: 0.3498976230621338\n",
      "epoch 80\n",
      "train loss: 5.3508592827711254e-06\t\teval loss: 0.3587622046470642\n",
      "epoch 90\n",
      "train loss: 3.5486284559738124e-06\t\teval loss: 0.37055879831314087\n",
      "epoch 100\n",
      "train loss: 2.4737930743867764e-06\t\teval loss: 0.38188862800598145\n",
      "\n",
      "epoch 100:\n",
      "\n",
      "f1_score for 50 classes: 0.6121343251268334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.97      0.48      0.64       125\n",
      "           9       0.75      0.57      0.65       231\n",
      "          22       0.74      0.56      0.64       212\n",
      "          35       0.86      0.38      0.52       189\n",
      "\n",
      "   micro avg       0.79      0.50      0.62       757\n",
      "   macro avg       0.83      0.50      0.61       757\n",
      "weighted avg       0.81      0.50      0.61       757\n",
      " samples avg       0.14      0.14      0.14       757\n",
      "\n",
      "\n",
      "Spent time: 789.3475403785706 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 110\n",
      "train loss: 1.4447028888753266e-06\t\teval loss: 0.399326354265213\n",
      "epoch 120\n",
      "train loss: 1.0577239208942046e-06\t\teval loss: 0.42101117968559265\n",
      "epoch 130\n",
      "train loss: 6.938356023056258e-07\t\teval loss: 0.4313143789768219\n",
      "epoch 140\n",
      "train loss: 4.216847173665883e-07\t\teval loss: 0.4309840202331543\n",
      "epoch 150\n",
      "train loss: 2.9583020477730315e-07\t\teval loss: 0.4396032392978668\n",
      "\n",
      "epoch 150:\n",
      "\n",
      "f1_score for 50 classes: 0.6235351641847177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.96      0.52      0.67       125\n",
      "           9       0.82      0.53      0.65       231\n",
      "          22       0.77      0.53      0.63       212\n",
      "          35       0.88      0.40      0.55       189\n",
      "\n",
      "   micro avg       0.84      0.50      0.62       757\n",
      "   macro avg       0.86      0.49      0.62       757\n",
      "weighted avg       0.84      0.50      0.62       757\n",
      " samples avg       0.14      0.13      0.13       757\n",
      "\n",
      "\n",
      "Spent time: 1173.1535396575928 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 160\n",
      "train loss: 2.1699578667266906e-07\t\teval loss: 0.4503426253795624\n",
      "epoch 170\n",
      "train loss: 1.5159817223775462e-07\t\teval loss: 0.46451789140701294\n",
      "epoch 180\n",
      "train loss: 1.2361311974018463e-07\t\teval loss: 0.48479682207107544\n",
      "epoch 190\n",
      "train loss: 7.876391094896462e-08\t\teval loss: 0.49246081709861755\n",
      "epoch 200\n",
      "train loss: 4.9944894442432997e-08\t\teval loss: 0.5033848285675049\n",
      "\n",
      "epoch 200:\n",
      "\n",
      "f1_score for 50 classes: 0.621377927356515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           8       0.96      0.52      0.67       125\n",
      "           9       0.83      0.53      0.65       231\n",
      "          22       0.75      0.53      0.62       212\n",
      "          35       0.88      0.39      0.54       189\n",
      "\n",
      "   micro avg       0.83      0.49      0.62       757\n",
      "   macro avg       0.86      0.49      0.62       757\n",
      "weighted avg       0.84      0.49      0.62       757\n",
      " samples avg       0.14      0.13      0.13       757\n",
      "\n",
      "\n",
      "Spent time: 1561.7246580123901 seconds\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod = final_model()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 200\n",
    "lr = 3e-4\n",
    "batch_size = 128\n",
    "norm = None\n",
    "\n",
    "hist = train_model(mod, train_, test_, device, norm,\n",
    "                lr=lr, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(hist['train_loss'], label='Train')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(hist['eval_loss'], label='Eval')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc35e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
